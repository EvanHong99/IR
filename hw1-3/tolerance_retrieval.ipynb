{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "\n",
    "## 作业三：\n",
    "## 实现容错的短语查询的布尔检索\n",
    "\n",
    "### 1、完成内容及思路：\n",
    "*实现的详细过程及各函数的作用、输入输出可以查看代码注释*\n",
    "\n",
    "- **对于‘·’、‘-’等连词符进行处理，使得能够将连词符两端的单词视为一个完整的单词**\n",
    "\n",
    "- 适当进行了异常处理，能够处理查询词不在词典中的问题\n",
    "\n",
    "- [build index]()\n",
    "\n",
    "初始化每个word的**`kgram`以及`soundex`编码**,并将其存放在index.npz中\n",
    "\n",
    "    :example defaultdict(<class 'list'>, {'advantages': ['\\$ad', 'adv', 'dva', 'van', 'ant', 'nta', 'tag', 'age', 'ges', 'es\\$'],\n",
    "\n",
    "- [get_k_gram]()\n",
    "\n",
    "获得一个单词的k-gram序列\n",
    "\n",
    "    将输入的词拆分成一个list，包含k-gram的内容\n",
    "    :param word: 一个单词，不带任何标点符号（除了连词符-）\n",
    "    :return:list\n",
    "- [edit dis]()\n",
    "\n",
    "计算编辑距离\n",
    "\n",
    "    :steps:\n",
    "        1、构建空符和两个单词字母的矩阵\n",
    "        2、初始化矩阵最左边和最上面\n",
    "        3、遍历计算，从左边的单词开始出发，计算每个待计算空格的值：\n",
    "            若横纵坐标字母不同：向下减字母，向右加字母(取决于哪里是目标单词）\n",
    "            若相同：不变\n",
    "    :param word1:\n",
    "    :param word2:\n",
    "    :return: int： edit distance\n",
    "- [correct]()\n",
    "\n",
    "进行word矫正，若和词库内的单词差距较大时不进行修正\n",
    "\n",
    "        :steps\n",
    "            进行将输入word拆分kgram；\n",
    "            和词典kgrams比较，计算jaccard系数，挑选较高的；\n",
    "            再计算编辑距离。\n",
    "            根据soundex编码进行矫正，优先级低于编辑距离矫正\n",
    "        :return:str： corrected word\n",
    "\n",
    "### 2、遇到的问题和不足：\n",
    "\n",
    "- 对于numpy和pandas的使用非常不熟练。。。但是又经常需要用到。希望能更加熟练掌握这个工具吧。\n",
    "\n",
    "- **本方法可以根据threshold进行阈值的调整以筛选jaccard系数较高的单词，再进行编辑距离的计算以及给出矫正结果。但是对于较短\n",
    "的单词（比如the），在k-gram=3时，无法进行校正。因为其jaccard系数为0.**\n",
    "\n",
    "- 发现之前代码的一个漏洞，之前只能处理能查找到的单词。现在在search函数中增加了异常处理，将未搜索到的单词给予用户反馈\n",
    "\n",
    "- 对于异常处理的应用不够广泛，仅仅在少数函数中使用。希望以后能加强异常处理意识"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# %% md\n",
    "\n",
    "# 作业一：布尔检索\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "\n",
    "# %% md\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "def get_words(text):\n",
    "    \"\"\"\n",
    "    构造dict，key为词，value为list，存放字的位置\n",
    "    :param text:\n",
    "    :return:defaultdict(<class 'list'>, {'a': [0, 2], 'aa': [1, 3], 'b': [4], 'c': [5], 'd': [6], 'e': [7], 'ff': [8], 'g': [9]})\n",
    "    \"\"\"\n",
    "    text = re.sub(r\"[{}]+\".format(punctuation), \" \", text)  # 将标点符号转化为空格\n",
    "    # print(text)\n",
    "    text = text.lower()  # 全部字符转为小写\n",
    "    words = nltk.word_tokenize(text)  # 分词\n",
    "    # print(words)\n",
    "    i = 0\n",
    "    result = defaultdict(list)\n",
    "    # words = list(set(words).difference(set(sw)))  # 去停用词\n",
    "    for word in words:\n",
    "        result[word].append(i)\n",
    "        i += 1\n",
    "    return result\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "def get_files(dir, file_type='.txt'):\n",
    "    '''\n",
    "    获取文件名列表\n",
    "    :param dir:\n",
    "    :param file_type:\n",
    "    :return:\n",
    "    '''\n",
    "    file_list = []\n",
    "    for home, dirs, files in os.walk(dir):\n",
    "        for filename in files:\n",
    "            if file_type in filename:\n",
    "                file_list.append(os.path.join(home, filename))\n",
    "    return file_list\n",
    "\n",
    "\n",
    "# 构造每种类型词的正则表达式，()代表分组，?P<NAME>为组命名\n",
    "token_or = r'(?P<OR>\\|\\|)'\n",
    "token_not = r'(?P<NOT>\\!)'\n",
    "token_word = r'(?P<WORD>([a-zA-Z]+(-|·){0,1})+)' #修改规则，使得能够识别连词符-和名字连接符·\n",
    "token_and = r'(?P<AND>&&)'\n",
    "token_lp = r'(?P<LP>\\()'\n",
    "token_rp = r'(?P<RP>\\))'\n",
    "token_quotation = r'(?P<QT>\\\")'\n",
    "\n",
    "\n",
    "lexer = re.compile('|'.join([token_or, token_not, token_word,\n",
    "                             token_and, token_lp, token_rp, token_quotation]))  # 编译正则表达式\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "# 用编译好的正则表达式进行词法分析\n",
    "def get_tokens(query):\n",
    "    \"\"\"\n",
    "[['\"', 'QT'], ['advantages', 'WORD'], ['clean', 'WORD'], ['\"', 'QT'], ['&&', 'AND'], ['\"', 'QT'],\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tokens = []  # tokens中的元素类型为(token, token类型)\n",
    "    for token in re.finditer(lexer, query):\n",
    "        tokens.append([token.group(), token.lastgroup])\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def soundex(string, size=4):\n",
    "    \"\"\"\n",
    "    将一个字符串编码为桑德斯编码\n",
    "    :type string:str\n",
    "    :rtype:str\n",
    "    :param string:\n",
    "    :param size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    #根据发音特点进行的桑德斯编码\n",
    "    soundex_digits = '01230120022455012623010202'\n",
    "    result = ''\n",
    "    first_char = ''\n",
    "    for c in string.upper():\n",
    "        # 如果是字母\n",
    "        if c.isalpha():\n",
    "            #若是第一个字母，则直接加入结果就行，不用soundex\n",
    "            if not first_char:\n",
    "                first_char = c\n",
    "            #否则进行桑德斯编码转换\n",
    "            d = soundex_digits[ord(c) - ord('A')]\n",
    "            #排除连续相似发音的单词\n",
    "            if not result or d != result[-1]:\n",
    "                result += d\n",
    "    result = first_char + result[1:]\n",
    "    #去掉['A','E','I','O','U','Y','H','W']等字母的发音\n",
    "    result = result.replace('0', '')\n",
    "    #补0拼接为结果\n",
    "    return (result + size * '0')[:size]\n",
    "\n",
    "\n",
    "\n",
    "class BoolRetrieval:\n",
    "    \"\"\"\n",
    "    布尔检索类\n",
    "    index为字典类型，其键为单词，值为文件ID列表，如{\"word\": [1, 2, 9], ...}\n",
    "    self.query_tokens为需要查询的词序列，list\n",
    "    self.files 文件名列表\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, index_path=''):\n",
    "        '''\n",
    "\n",
    "        :param index_path:\n",
    "        '''\n",
    "        if index_path == '':\n",
    "            self.index = defaultdict(list)\n",
    "            self.k_gram_val = defaultdict(list)\n",
    "            self.soundex=defaultdict(list)\n",
    "\n",
    "        # 已有构建好的索引文件\n",
    "        else:\n",
    "            data = np.load(index_path, allow_pickle=True)\n",
    "            self.files = data['files'][()]  # ()用来填充，否则报错。可以获取文件中所有该key下的内容，此处key为files\n",
    "            self.index = data['index'][()]\n",
    "            self.k_gram_val=data['k_gram'][()]\n",
    "            self.soundex=data['soundex'][()]\n",
    "            # print(self.index)\n",
    "        self.query_tokens = []\n",
    "        self.k_num=3\n",
    "\n",
    "\n",
    "    def build_index(self, text_dir):\n",
    "        \"\"\"\n",
    "        1、\n",
    "            self.index={key:{doc_num:[word_place]}}\n",
    "            :example: {'the': {1: [0, 17, 20, 36, 50, 56, 73, 76], 2: [47, 71, 76, 83], 3: [4, 39, 56]}}\n",
    "            self.index就像是一个字典的列表，索引键为词，索引值为所在文档的序号\n",
    "            在索引的构建过程中，不仅需要记录单词出现的文档，还要记录单词在文档中出现的位置，因\n",
    "            此索引结构要进行相应的改变 (图 1)。另外在分词的时候停用词和标点都需要保留以确保短语的完\n",
    "            整性。\n",
    "        2、\n",
    "            初始化每个word的kgram\n",
    "            :example defaultdict(<class 'list'>, {'advantages': ['$ad', 'adv', 'dva', 'van', 'ant', 'nta', 'tag', 'age', 'ges', 'es$'],\n",
    "        3.\n",
    "            将桑德斯编码后的结果存入索引\n",
    "        :param text_dir:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.files = get_files(text_dir)  # 获取所有文件名\n",
    "        self.index = {}\n",
    "        self.soundex={}\n",
    "        for num in range(0, len(self.files)):\n",
    "            f = open(self.files[num])\n",
    "            text = f.read()\n",
    "            # words格式为：defaultdict(<class 'list'>, {'a': [0, 2], 'aa': [1, 3], 'b': [4], 'c': [5], 'd': [6],\n",
    "            # 'e': [7], 'ff': [8], 'g': [9]})\n",
    "            words = get_words(text)  # 分词\n",
    "\n",
    "            # 构建倒排索引、k-gram\n",
    "            for word in words.keys():\n",
    "                # self.index[word]={num:words.get(word)}\n",
    "                temp = {num: words.get(word)}\n",
    "                sound=soundex(word)\n",
    "                # print(temp)\n",
    "                #如果之前没有这个词，加入word\n",
    "                if self.index.get(word) == None:\n",
    "                    self.index[word] = temp\n",
    "                else:#若有这个词，则在对应的word下加入相应num和其值\n",
    "                    self.index[word][num] = words.get(word)\n",
    "\n",
    "\n",
    "                #进行k-gram拆解\n",
    "\n",
    "                self.k_gram_val[word]=self.get_k_gram(word)\n",
    "\n",
    "                #soundex\n",
    "                if not self.soundex.get(sound):\n",
    "                    self.soundex[sound]=[word]\n",
    "                else:\n",
    "                    self.soundex[sound].append(word)\n",
    "\n",
    "\n",
    "        # print(self.files, self.index)\n",
    "        np.savez('index.npz', files=self.files, index=self.index,k_gram=self.k_gram_val,soundex=self.soundex)\n",
    "\n",
    "    def get_k_gram(self,word):\n",
    "        \"\"\"\n",
    "        将输入的词拆分成一个list，包含k-gram的内容\n",
    "        :param word: 一个单词，不带任何标点符号（除了连词符-）\n",
    "        :return:list\n",
    "        \"\"\"\n",
    "        temp_word = '$' + word + '$'\n",
    "        k_gram_list = []\n",
    "        for i in range(len(temp_word) + 1 - self.k_num):\n",
    "            k_gram_list.append(temp_word[i:i + self.k_num])\n",
    "        return k_gram_list\n",
    "\n",
    "    def edit_dis(self,word1,word2):\n",
    "        \"\"\"\n",
    "        计算编辑距离\n",
    "\n",
    "        :steps:\n",
    "            1、构建空符和两个单词字母的矩阵\n",
    "            2、初始化矩阵最左边和最上面\n",
    "            3、遍历计算，从左边的单词开始出发，计算每个待计算空格的值：\n",
    "                若横纵坐标字母不同：向下减字母，向右加字母(取决于哪里是目标单词）\n",
    "                若相同：不变\n",
    "        :param word1:\n",
    "        :param word2:\n",
    "        :return: int： edit distance\n",
    "        \"\"\"\n",
    "        m=np.mat(np.zeros((len(word1)+1,len(word2)+1)))\n",
    "        m[:,0]=np.mat(np.arange(len(word1)+1)).T\n",
    "        m[0,:]=np.arange(len(word2)+1)\n",
    "        # print(m)\n",
    "        for i in range(1,len(word1)+1):\n",
    "            for j in range(1,len(word2)+1):\n",
    "                m[i,j]=min(m[i-1,j-1] if word1[i-1]==word2[j-1] else m[i-1,j-1]+1,m[i-1,j]+1,m[i,j-1]+1)\n",
    "        # print(m)\n",
    "        return m[-1,-1]\n",
    "\n",
    "\n",
    "\n",
    "    def correct(self, word):\n",
    "        \"\"\"\n",
    "        进行word矫正\n",
    "\n",
    "        :steps\n",
    "            进行将输入word拆分kgram；\n",
    "            和词典kgrams比较，计算jaccard系数，挑选较高的；\n",
    "            再计算编辑距离。\n",
    "            若编辑距离较大，则进行soundex矫正\n",
    "        :return:str： corrected word\n",
    "        \"\"\"\n",
    "        # 进行将输入word拆分kgram；\n",
    "        threshold=0.3\n",
    "        top_num=5\n",
    "\n",
    "        word_k=set(self.get_k_gram(word))\n",
    "\n",
    "        #             和词典kgrams比较，计算jaccard系数，挑选较高的；\n",
    "        indicator=pd.DataFrame(columns=['word','jaccard'])\n",
    "        for w in self.index.keys():\n",
    "            w_set=set(self.k_gram_val[w])\n",
    "            intsct=len((w_set.intersection(word_k)))\n",
    "            union= len(w_set) + len(word_k)-intsct\n",
    "            jaccard=intsct/union\n",
    "            indicator=indicator.append({'word':w,'jaccard':jaccard},ignore_index=True)\n",
    "        indicator.sort_values(by='jaccard', ascending=False, inplace=True)\n",
    "        num=min(top_num,len(indicator.loc[indicator['jaccard'] > threshold]))\n",
    "        top_words=indicator.head(num)\n",
    "\n",
    "        # 再计算编辑距离。\n",
    "        s=pd.Series(float)\n",
    "        for e in top_words['word']:\n",
    "            dis=self.edit_dis(word,e)\n",
    "            s[e]=dis if dis<4 else 7\n",
    "        # 第一行是标题行\n",
    "        if s.size>1 and s.values[1]<4:\n",
    "            print('矫正单词为：', s.keys()[1])\n",
    "            return s.keys()[1]\n",
    "        else:#未完善！=================================================\n",
    "            trigger=self.soundex.get(soundex(word))\n",
    "            if trigger:\n",
    "                print('soundex矫正为 ',trigger[0])\n",
    "                return trigger[0]#不是word第一个单词，而是应该最接近的哪一个\n",
    "            else:\n",
    "                print('未矫正单词')\n",
    "                return word\n",
    "\n",
    "    def search(self, query):\n",
    "        \"\"\"\n",
    "        bool retrieval功能的统一入口\n",
    "        1. 进行拼写矫正\n",
    "        :param query: 查询的句子\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.query_tokens = get_tokens(query)  # 获取查询的tokens\n",
    "            for i in range(len(self.query_tokens)):\n",
    "                if self.query_tokens[i][1] =='WORD' and (self.query_tokens[i][0] not in self.index.keys()):\n",
    "                    self.query_tokens[i]=[self.correct(self.query_tokens[i][0]), 'WORD']\n",
    "\n",
    "            result = []\n",
    "            # 将查询得到的文件ID转换成文件名\n",
    "            for num in self.evaluate(0, len(self.query_tokens) - 1):\n",
    "                result.append(self.files[num])\n",
    "            return result\n",
    "        except Exception:\n",
    "\n",
    "            return '无查找结果'\n",
    "\n",
    "    # 递归解析布尔表达式，p、q为子表达式左右边界的下标\n",
    "    def evaluate(self, p, q):\n",
    "        \"\"\"\n",
    "\n",
    "        :param p:\n",
    "        :param q:\n",
    "        :return: list, indexes of files that contains the string queried\n",
    "        \"\"\"\n",
    "        # 解析错误\n",
    "        if p > q:\n",
    "            return []\n",
    "        # 单个token，一定为查询词\n",
    "        elif p == q:\n",
    "            if self.index.get(self.query_tokens[p][0]):\n",
    "                return list(self.index[self.query_tokens[p][0]].keys())\n",
    "        # 去掉外层括号\n",
    "        elif self.check_parentheses(p, q):\n",
    "            return self.evaluate(p + 1, q - 1)\n",
    "        elif self.check_quotation(p, q):  # 被 双 引 号 包 围 的 短 语 ， 注 意 双 引 号 中 间 不 应 有 其 他 双 引 号 或 逻 辑 运 算 符\n",
    "\n",
    "            return self.phrase_search(p + 1, q - 1)\n",
    "        else:\n",
    "            # 非单个token\n",
    "            op, and_list = self.find_operator(p, q)\n",
    "            # 只有一个and运算符\n",
    "            if len(and_list) == 1 or not and_list:\n",
    "                if op == -1:\n",
    "                    return []\n",
    "                # files1为运算符左边得到的结果，files2为右边\n",
    "                if self.query_tokens[op][1] == 'NOT':\n",
    "                    files1 = []\n",
    "                else:\n",
    "                    files1 = self.evaluate(p, op - 1)\n",
    "                files2 = self.evaluate(op + 1, q)\n",
    "                return self.merge(files1, files2, self.query_tokens[op][1])\n",
    "            else:\n",
    "                if op == -1:\n",
    "                    return []\n",
    "                # files1为运算符左边得到的结果，files2为右边\n",
    "                if self.query_tokens[op][1] == 'NOT':\n",
    "                    files1 = []\n",
    "                elif self.query_tokens[op][1] == 'AND':  # 最小优先级为and，且有多个and\n",
    "\n",
    "                    # 将p和q加入列表，方便统一格式\n",
    "                    and_list.insert(0, p - 1)\n",
    "                    and_list.insert(len(and_list), q + 1)\n",
    "                    num_and = len(and_list)\n",
    "                    files = []\n",
    "                    # files.append(len(self.evaluate(p,and_list[0]-1)))\n",
    "                    i = 0\n",
    "                    while i < num_and - 1:\n",
    "                        files.append(len(self.evaluate(and_list[i] + 1, and_list[i + 1] - 1)))\n",
    "                        i += 1\n",
    "                    # files.append(len(self.evaluate(and_list[-1]+1,q)))\n",
    "                    print('出现多个and的情况，进行优化')\n",
    "                    print('各个段出现文章的个数分别为：', files)\n",
    "                    temp = list(pd.Series(files).sort_values()[:2].index)\n",
    "                    print('即将进行运算的是以下两个段：', temp)\n",
    "                    #需要将query tokens进行调序，将文件数较少的两个放到前面来\n",
    "                    tuples=[]\n",
    "                    for t in range(len(files)):\n",
    "                        tuples.append(self.query_tokens[(and_list[t]+1):(and_list[t+1])])# 将token序列根据and切分开来，后半部分不用减1，因为是：\n",
    "                    self.query_tokens=tuples[temp[0]]+[('&&','AND')]+tuples[temp[1]]\n",
    "                    tuples.pop(temp[0])\n",
    "                    tuples.pop(temp[1]-1)# 必须保证前面pop的元素在此元素前\n",
    "                    for tpl in tuples:\n",
    "                        self.query_tokens=self.query_tokens+[('&&','AND')]+tpl\n",
    "                    #重新寻找第一个and\n",
    "                    op, and_list = self.find_operator(p, q)\n",
    "                    files1 = self.evaluate(p,op-1)\n",
    "                    files2 = self.evaluate(op+1,q)\n",
    "\n",
    "                    return self.merge(files1, files2, self.query_tokens[op][1])\n",
    "\n",
    "\n",
    "\n",
    "                else:\n",
    "                    files1 = self.evaluate(p, op - 1)\n",
    "                files2 = self.evaluate(op + 1, q)\n",
    "                return self.merge(files1, files2, self.query_tokens[op][1])\n",
    "\n",
    "    # 判断表达式是否为 (expr)\n",
    "    # 判断表达式是否为 (expr)\n",
    "    def check_parentheses(self, p, q):\n",
    "        \"\"\"\n",
    "        判断表达式是否为 (expr)\n",
    "        整个表达式的左右括号必须匹配才为合法的表达式\n",
    "        返回True或False\n",
    "\n",
    "        #注意(based!day)&&(based&&day)\n",
    "        \"\"\"\n",
    "        LP = 0\n",
    "        if (self.query_tokens[p][0] == '(') & (self.query_tokens[q][0] == ')'):\n",
    "            i = p + 1\n",
    "            while (i < q):\n",
    "                if self.query_tokens[i][0] == ')':\n",
    "                    LP -= 1\n",
    "                    if LP < 0: return False\n",
    "                elif self.query_tokens[i][0] == '(':\n",
    "                    LP += 1\n",
    "                i += 1\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def check_quotation(self, p, q):\n",
    "        \"\"\"\n",
    "        检查英文引号配对\n",
    "        # 被 双 引 号 包 围 的 短 语 ， 注 意 双 引 号 中 间 不 应 有 其 他 双 引 号 或 逻 辑 运 算 符\n",
    "        :param p:\n",
    "        :param q:\n",
    "        :return: true or false\n",
    "        \"\"\"\n",
    "        if self.query_tokens[p][1] == 'QT' and self.query_tokens[q][1] == 'QT':\n",
    "            for i in range(p + 1, q):\n",
    "                if self.query_tokens[i][1] != 'WORD': return False\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def phrase_search(self, p, q):\n",
    "        \"\"\"\n",
    "        短语查询\n",
    "        :param p:\n",
    "        :param q:\n",
    "        :return: list,短语查询结果\n",
    "        \"\"\"\n",
    "        # {'a': {1:[0, 2],2:[6,6,6,6]}}\n",
    "\n",
    "        result = list(self.index[self.query_tokens[p][0]])\n",
    "        # 构建一个list，包含短语中每个词（此处无所谓这个词是啥了，只需要考虑各个词之间的shunxuguanxi)\n",
    "        # 先确定所有共同的文档index\n",
    "        \"\"\"#不确定是否上界为q\"\"\"\n",
    "        for i in range(p + 1, q + 1):\n",
    "            result = set(result).intersection(set(self.index[self.query_tokens[i][0]]))\n",
    "            if not result:\n",
    "                return []\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        # 再确定在共同的文档中是否是短语，因此每次只筛选一个文档，若没有交集则将该文档从result删除\n",
    "        for file_num in result:\n",
    "            # temp用来存word的位置，不需要考虑文档编号，因为已经在上面的循环刨去文档数了，现在所有word都是能出现在同一个文档里的\n",
    "            temp = self.index[self.query_tokens[p][0]][file_num]\n",
    "            for i in range(p + 1, q + 1):\n",
    "                # 求列表交集\n",
    "                temp = set([t + 1 for t in temp]).intersection(set(self.index[self.query_tokens[i][0]][file_num]))\n",
    "                if not temp:\n",
    "                    result.remove(file_num)\n",
    "        return list(result)\n",
    "        # word_dict_list = []  # [{1:[0, 2],2:[6,6,6,6]},{1:[0, 2],2:[6,6,6,6]}...]\n",
    "        # for i in range(p + 1, q):\n",
    "        #     word_dict_list.append(self.index[self.query_tokens[i][0]])\n",
    "        # for file_index in word_dict_list[0].keys():\n",
    "        #     for word_dict in word_dict_list:\n",
    "\n",
    "    # 寻找表达式的dominant的运算符（优先级最低）\n",
    "    def find_operator(self, p, q):\n",
    "        \"\"\"\n",
    "        寻找表达式的dominant的运算符（优先级最低）\n",
    "        其必定在括号外面（不存在整个子表达式被括号包围，前面以已处理）\n",
    "        返回dominant运算符的下标位置\n",
    "        \"\"\"\n",
    "        # 找出第一个非括号运算符，并将其位置记录在列表中\n",
    "        LP = 0\n",
    "        lowest_op = 'NOT'\n",
    "        first_and = -1\n",
    "        first_not = -1\n",
    "        and_list = []\n",
    "        while p < q:\n",
    "            temp_token = self.query_tokens[p][1]\n",
    "            if temp_token != 'WORD' and temp_token != 'QT':\n",
    "                if temp_token == 'LP':\n",
    "                    LP += 1\n",
    "                elif temp_token == 'RP':\n",
    "                    LP -= 1\n",
    "                elif LP == 0:\n",
    "                    if temp_token == 'OR':\n",
    "                        return p, []\n",
    "                    elif temp_token == 'AND':\n",
    "                        lowest_op = 'AND'\n",
    "                        if first_and == -1: first_and = p\n",
    "                        and_list.append(p)\n",
    "                    elif temp_token == 'NOT':\n",
    "                        if first_not == -1: first_not = p\n",
    "\n",
    "            p += 1\n",
    "        if lowest_op == 'AND':\n",
    "            return first_and, and_list\n",
    "        else:\n",
    "            return first_not, []\n",
    "\n",
    "    def merge(self, files1, files2, op_type):\n",
    "        \"\"\"\n",
    "        根据运算符对进行相应的操作\n",
    "        在Python中可以通过集合的操作来实现\n",
    "        但为了练习算法，请遍历files1, files2合并\n",
    "        \"\"\"\n",
    "        result = []\n",
    "\n",
    "        if op_type == 'AND':\n",
    "            # result = list(set(files1) & set(files2))\n",
    "            result = [item for item in files1 if item in files2]\n",
    "        elif op_type == \"OR\":\n",
    "            # result = list(set(files1) | set(files2))\n",
    "            temp_file_list = files1 + files2\n",
    "            if temp_file_list:\n",
    "                result = pd.array(temp_file_list).unique().to_numpy().tolist()\n",
    "        elif op_type == \"NOT\":\n",
    "            # result = list(set(range(0, len(self.files))) - set(files2))\n",
    "            # all_files=np.array()\n",
    "\n",
    "            result = [item for item in range(0, len(self.files)) if item not in files2]\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "矫正单词为： advantages\n",
      "['text\\\\advantages.txt']\n",
      "['text\\\\advantages.txt']\n",
      "未矫正单词\n",
      "无查找结果\n",
      "soundex矫正为  activity\n",
      "['text\\\\ir.txt']\n"
     ]
    }
   ],
   "source": [
    "br = BoolRetrieval()\n",
    "br.build_index('text')\n",
    "br = BoolRetrieval('index.npz')\n",
    "# print(br.search('\\\"clean\\\"&&\\\"easy to implement\\\"&&adavntages'))\n",
    "# print(br.search('\\\"adavntages clean\\\"&&\\\"easy to implement\\\"'))\n",
    "print(br.search('adavntages'))\n",
    "print(br.search('advantages'))\n",
    "print(br.search('oh-my-god'))\n",
    "print(br.search('actvty'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**可以看到上面的测试字符序列中，advantages的拼写是错误的，\n",
    "但是通过矫正后得出和advantages一样的正确的结果。\n",
    "此外，当查询actvty时，会根据判断规则进行soundex编码校正，给出正确结果activity以及其文档位置**"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}